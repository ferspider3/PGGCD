{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregar os dados\n",
    "file_path = 'emprego.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Exibir as primeiras linhas do conjunto de dados\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Análise de correlação apenas das colunas numéricas\n",
    "num_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "corr = data[num_cols].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cd355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separar as features do target\n",
    "X = data.drop(columns=['sl_no', 'salary', 'status'])\n",
    "y = data['salary']\n",
    "\n",
    "# Preencher os valores NaN na coluna de salário com a mediana\n",
    "y.fillna(y.median(), inplace=True)\n",
    "\n",
    "# Normalizar a variável de destino (y)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Identificar colunas numéricas e categóricas\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Criar transformers para colunas numéricas e categóricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Criar um pré-processador que aplica os transformers adequados\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicar a transformação aos dados\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Garantir que não há valores NaN em y_train e y_test\n",
    "y_train = np.nan_to_num(y_train)\n",
    "y_test = np.nan_to_num(y_test)\n",
    "\n",
    "# Verificar os dados após a normalização\n",
    "print(\"Primeiros 5 registros de X_train após normalização:\")\n",
    "print(X_train[:5])\n",
    "print(\"Estatísticas descritivas de X_train:\")\n",
    "print(pd.DataFrame(X_train).describe())\n",
    "\n",
    "# Verificar outliers extremos nas colunas numéricas originais\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=data[num_cols])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regressão Linear\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Random Forest com ajuste de hiperparâmetros\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Rede Neural Artificial com parâmetros ajustados e normalização de X\n",
    "nn_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(5,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.0001,\n",
    "    alpha=0.1,\n",
    "    max_iter=1000,\n",
    "    shuffle=True,\n",
    "    validation_fraction=0.2,\n",
    "    random_state=20,\n",
    "    verbose=True\n",
    ")\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "y_pred_nn = scaler_y.inverse_transform(y_pred_nn.reshape(-1, 1)).flatten()  # Inverter normalização\n",
    "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"Regressão Linear - MSE:\", mse_lr, \"R^2:\", r2_lr)\n",
    "print(\"Random Forest - MSE:\", mse_rf, \"R^2:\", r2_rf)\n",
    "print(\"Rede Neural - MSE:\", mse_nn, \"R^2:\", r2_nn)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
